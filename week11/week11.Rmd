---
title: "SML 201 -- Week 11"
author: "John D. Storey"
date: "Spring 2016"
output:
  revealjs::revealjs_presentation:
    center: yes
    highlight: null
    theme: simple
    transition: slide
    includes:
      before_body: ../customization/doc_prefix.html
---

```{r my_opts, cache=FALSE, include=FALSE}
library(knitr)
knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(4, 4, .1, .1))  # smaller margin on top and right
})
opts_chunk$set(fig.align="center", fig.height=5.5, fig.width=6.75, collapse=TRUE, comment="", prompt=TRUE, small.mar=TRUE)
options(width=63)
library("ggplot2")
theme_set(theme_bw())
library("dplyr")
library("broom")
set.seed(201)
```

# <img src="../images/howto.jpg"></img>

# Statistics, ML, and Data Science

## Statistics

**Statistics** is the study of the collection, analysis, interpretation, presentation, and organization of data.

<https://en.wikipedia.org/wiki/Statistics>

## Machine Learning

**Machine learning** explores the study and construction of algorithms that can learn from and make predictions on data. Machine learning is closely related to and often overlaps with computational statistics; a discipline which also focuses in prediction-making through the use of computers. 

<https://en.wikipedia.org/wiki/Machine_learning>

## Data Science

**Data Science** is an interdisciplinary field about processes and systems to extract knowledge or insights from data in various forms, either structured or unstructured, which is a continuation of some of the data analysis fields such as statistics, data mining, and predictive analytics.

<https://en.wikipedia.org/wiki/Data_science>

# Learning

## A Definition

[Statistical learning](https://www.google.com/search?q=statistical+learning) (or statistical machine learning) is largely about using statistical modeling ideas to solve machine learning problems.  

"Learning" basically means using data to build or fit models.

## Quotations

From [*An Introduction to Statistical Learning*](http://www-bcf.usc.edu/~gareth/ISL/):

"Statistical learning refers to a vast set of tools for understanding data."

"Though the term statistical learning is fairly new, many of the concepts that underlie the field were developed long ago."

"Inspired by the advent of machine learning and other disciplines, statistical learning has emerged as a new subfield in statistics, focused on supervised and unsupervised modeling and prediction."

# A Modeling Framework

## Ordinary Least Squares

Suppose we observe data $(x_{11}, x_{21}, \ldots, x_{d1}, y_1), \ldots$, $(x_{1n}, x_{2n}, \ldots, x_{dn}, y_n)$.  We have a response variable $y_i$ and $d$ explanatory variables $(x_{1i}, x_{2i}, \ldots, x_{di})$ per unit of observation.

Ordinary least squares models the variation of $y$ in terms of $\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_d x_d$.

## OLS Model

The assumed model is

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_d X_{di} + E_i$$

where ${\rm E}[E_i] = 0$, ${\rm Var}(E_i) = \sigma^2$, and $\rho_{E_i, E_j} = 0$ for all $1 \leq i, j \leq n$ and $i \not= j$.

## A More General Model

Let's collapse $X_i = (X_{1i}, X_{2i}, \ldots, X_{di})$.  A more general model is

$$Y_i = f(X_i) + E_i,$$

with the same assumptions on $E_i$, for some function $f$ that maps the $d$ variables into the real numbers.

## Modeling Fitting

<center>![fig 2.2](images/fig_2-2.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

## Example True Model

<center>![fig 2.3](images/fig_2-3.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

## OLS Linear Model

<center>![fig 2.4](images/fig_2-4.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

## A Flexible Model

<center>![fig 2.5](images/fig_2-5.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

## Variable Names

Input variables $(X_{1}, X_{2}, \ldots, X_{d})$:

- explanatory variables
- covariates
- predictors
- independent variables
- feature variables 

Output variable $(Y)$:

- response variable
- dependent variable
- label
- outcome variable

## Learning Types

**Supervised learning** is aimed at fitting models to $(X,Y)$ so that we can model the output $Y$ given the input $X$, typically on future observations.  **Prediction models**  are built by supervised learning.

**Unsupervised learning** (next week's topic) is aimed at fitting models to $X$ alone to charcaterize the distribution of or find patterns in $X$.

## Prediction

We often want to fit $Y = f(X) + E$ for either **prediction** or **inference**.

When observed $x$ are readily available but $y$ is not, the goal is usually *prediction*.  If $\hat{f}(x)$ is the estimated model, we predict $\hat{y} = \hat{f}(x)$ for an observed $x$.  Here, $\hat{f}$ is often treated as a black box and we mostly care that it provides accurate predictions.

## Inference

When we co-observe $x$ and $y$, we are often interested in understanding the way that $y$ is explained by varying $x$ or is a causal effect of $x$ -- and we want to be able to explicitly quantify these relationships.  This is the goal of *inference*.  Here, we want to be able to estimate and interpret $f$ as accurately as possible -- and have it be as close as possible to the underlying real-world mechanism connecting $x$ to $y$.

## Regression vs Classification

When $Y \in (-\infty, \infty)$, learning $Y = f(X) + E$ is called **regression**.

When $Y \in \{0,1\}$ or more generally $Y \in \{c_1, c_2, \ldots, c_K\}$, we want to learn a function $f(X)$ that takes values in $\{c_1, c_2, \ldots, c_K\}$ so that ${\rm Pr}\left(Y=f(X)\right)$ is as large as possible.  This is called **classification**.

## Parametric vs Nonparametric

A **parametric** model is a pre-specified form of $f(X)$ whose terms can be characterized by a formula and interpreted. This usually involves parameters on which inference can be performed, such as coefficients in the OLS model.

A **nonparametric** model is a data-driven form of $f(X)$ that is often very flexible and is not easily expressed or intepreted.  A nonparametric model often does not include parameters on which we can do inference.

# Accuracy of Learners

## Decomposing Error

Let $\hat{Y} = \hat{f}(X)$ be the output of the learned model.  Suppose that $\hat{f}$ and $X$ are fixed.  We can then define the error of this fitted model by:

\begin{eqnarray}
{\rm E}\left[\left(Y - \hat{Y}\right)^2\right] & = & {\rm E}\left[\left(f(X) + E - \hat{f}(X)\right)^2\right] \\
\ & = & {\rm E}\left[\left(f(X) - \hat{f}(X)\right)^2\right] + {\rm Var}(E)
\end{eqnarray}

The term ${\rm E}\left[\left(f(X) - \hat{f}(X)\right)^2\right]$ is the **reducible error** and the term ${\rm Var}(E)$ is the **irreducible error**.

## Error Rates

On an observed data set $(x_1, y_1), \ldots, (x_n, y_n)$ we usually calculate error rates as follows.

For regression, we calculate the mean-squared error:

$$\mbox{MSE} = \frac{1}{n} \sum_{i=1}^n \left(y_i - \hat{f}(x_i)\right)^2.$$

For classification, we calculate the misclassification rate:

$$\mbox{MCR} = \frac{1}{n} \sum_{i=1}^n 1[y_i \not= \hat{f}(x_i)],$$

where $1[\cdot]$ is 0 or 1 whether the argument is false or true, respectively.

## Training vs Testing

We typically fit the model on one data set and then assess its accuracy on an independent data set.  

The data set used to fit the model is called the **training data set**.

The data set used to test the model is called the **testing data set** or **test data set**.

## Important Questions

1.  Why do we need training and testing data sets to accurately assess a learned model's accuracy?

2.  How is this approach notably different from the inference approach we learned earlier?

## Overfitting

**Overfitting** is a very important concept in statistical machine learning.

It occurs when the fitted model follows the noise term too closely.

In other words, when $\hat{f}(X)$ is overfitting the $E$ term in  $Y = f(X) + E$.

## Performance of Different Models

<center>![fig 2.9](images/fig_2-9.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

----

<center>![fig 2.9-2](images/fig_2-9-2.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

----

<center>![fig 2.10](images/fig_2-10.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

----

<center>![fig 2.11](images/fig_2-11.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>


# Trade-offs

## Some Trade-offs

There are several important trade-offs encountered in prediction or learning:

- Bias vs variance
- Accuracy vs computational time
- Flexibility vs intepretability

These are not mutually exclusive phenomena.

## Bias and Variance

\begin{eqnarray}
{\rm E}\left[\left(Y - \hat{Y}\right)^2\right] & = & {\rm E}\left[\left(f(X) + E - \hat{f}(X)\right)^2\right] \\
\ & = & {\rm E}\left[\left(f(X) - \hat{f}(X)\right)^2\right] + {\rm Var}(E) \\
\ & = & \left(f(X) - {\rm E}[\hat{f}(X)]\right)^2 + {\rm Var}\left(\hat{f}(X)\right)^2 + {\rm Var}(E) \\ 
\ & = & \mbox{bias}^2 + \mbox{variance} + {\rm Var}(E)
\end{eqnarray}

## Flexibility vs Interpretability

<center>![fig 2.7](images/fig_2-7.tiff)</center>

<font size=1em>
Figure credit: [*ISL*](http://www-bcf.usc.edu/~gareth/ISL/)
</font>

# Logistic Regression

## Definition

Logistic regression models Binomial distributed response variable in terms of linear combinations of explanatory variables.

## Example: Grad School Admissions

```{r}
mydata <- 
  read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
dim(mydata)
head(mydata)
```

Data and analysis courtesy of <http://www.ats.ucla.edu/stat/r/dae/logit.htm>.


## Explore the Data

```{r}
apply(mydata, 2, mean)
apply(mydata, 2, sd)

table(mydata$admit, mydata$rank)
```

----

```{r}
ggplot(data=mydata) +
  geom_boxplot(aes(x=as.factor(admit), y=gre))
```

----

```{r}
ggplot(data=mydata) +
  geom_boxplot(aes(x=as.factor(admit), y=gpa))
```

## The Model

Suppose we observe data $(x_{11}, x_{21}, \ldots, x_{d1}, y_1), \ldots$, $(x_{1n}, x_{2n}, \ldots, x_{dn}, y_n)$.  We have a response variable $y_i$ and $d$ explanatory variables $(x_{1i}, x_{2i}, \ldots, x_{di})$ per unit of observation.

The assumption is that $y$ is a realization from a $Y \sim \mbox{Binomia}(1,p)$ distribution where:

$$\operatorname{log}\left( \frac{p}{1-p}\right) =
\operatorname{log}\left( \frac{\operatorname{Pr}(Y=1)}{\operatorname{Pr}(Y=0)}\right) = 
\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_d X_d
$$

## Logit Function

The logit function is

$$
\operatorname{logit}(p) = \operatorname{log}\left( \frac{p}{1-p}\right)
$$

for $0 < p < 1$.  The inverse logit function is

$$
\operatorname{logit}^{-1}(x) = \frac{e^x}{1+e^x}.
$$

## Fitting the Model

Logistic regression models are fit by finding the [maximum likelihood estimate](https://en.wikipedia.org/wiki/Maximum_likelihood) of $p$ through and algorithm called [iteratively reweighted least squares](https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares).

## Logistic Regression in R

```{r}
mydata$rank <- factor(mydata$rank, levels=c(1, 2, 3, 4))
myfit <- glm(admit ~ gre + gpa + rank, 
             data = mydata, family = "binomial")
myfit
```

## Summary of Fit

```{r}
summary(myfit)
```

## ANOVA of Fit

```{r}
anova(myfit, test="Chisq")
```

## Example: Contraceptive Use

```{r}
cuse <- 
  read.table("http://data.princeton.edu/wws509/datasets/cuse.dat", 
             header=TRUE)
dim(cuse)
head(cuse)
```

Data and analysis courtesy of <http://data.princeton.edu/R/glms.html>.

## A Different Format

Note that in this data set there are multiple observations per explanatory variable configuration.

The last two columns of the data frame count the successes and failures per configuration.

```{r}
head(cuse)
```

## Fitting the Model

When this is the case, we call the `glm()` function slighlty differently.

```{r}
myfit <- glm(cbind(using, notUsing) ~ age + education + 
               wantsMore, data=cuse, family = binomial)
myfit
```

## Summary of Fit

```{r}
summary(myfit)
```

## ANOVA of Fit

```{r}
anova(myfit, test="Chisq")
```

## More on this Data Set

See <http://data.princeton.edu/R/glms.html> for more on fitting logistic regression to this data set.

A number of interesting choices are made that reveal more about the data and the ways that logistic regression can be utilized.


# Spam Example

## The Data

We will analyze a data set for determining whether an email is spam or not.  The data can be found [here](https://archive.ics.uci.edu/ml/datasets/Spambase), and it is also available in the [kernal](http://www.inside-r.org/packages/cran/kernlab/docs/spam) R package.

```{r, message=FALSE}
library("dplyr")
library("kernlab")
library("broom")
data("spam")
spam <- tbl_df(spam)
names(spam)
```

##  Contents of the Data Set

```{r}
dim(spam)
head(spam)
```

## Convert the Response Variable

```{r}
spam <- spam %>% 
        mutate(response=as.numeric(type=="spam")) %>% 
        select(-type)
mean(spam$response)
```

## Logistic Regression: 1 Variable

```{r}
myfit <- glm(response ~ edu, family=binomial, data=spam)
myfit
```

## Summary

```{r}
summary(myfit)
```

## Logit Function

```{r}
logit <- function(p, tol=1e-10) {
  p <- pmin(pmax(tol, p), 1-tol)
  log(p/(1-p))
}
```

## Visualization

```{r}
plot(spam$edu, myfit$fitted.values)
```

## Visualization

```{r}
plot(spam$edu, logit(myfit$fitted.values))
```

## Logistic Regression: All Variables

```{r}
myfit <- glm(response ~ ., family=binomial, data=spam)
x <- tidy(myfit)
head(x)
```

## Misclassification Rate (Biased)

```{r}
pred_response <- as.numeric(myfit$fitted.values >= 0.5)
mean(pred_response == spam$response)
```

## Probabilites on Full Data Fit

```{r}
boxplot(myfit$fitted.values[spam$response==0], 
        myfit$fitted.values[spam$response==1])
```


## Train and Test Sets

```{r}
set.seed(210)
v <- sample(nrow(spam), size=round(2*nrow(spam)/3))
spam0 <- spam[v,]  ## training data
spam1 <- spam[-v,]  ## test data
fit0 <- glm(response ~ ., family=binomial, data=spam0)
pred_prob <- predict(fit0, newdata=spam1[,-ncol(spam1)], 
                     type="response")
```

## Trained Probabilities on Test Set

```{r}
boxplot(pred_prob[spam1$response==0], 
        pred_prob[spam1$response==1])
```

## Misclassification Rate (Unbiased)

```{r}
pred_response <- as.numeric(pred_prob >= 0.5)
mean(pred_response == spam1$response)
```

# A Prediction Framework in R

## The `caret` Package

R has several convenient frameworks for building and evaluating prediction models.

One of them is contained in the package `caret`. 

We will go through an example, courtesy of [this *RPubs* publication](https://rpubs.com/JaysonSunshine/61844).

```{r, message=FALSE, warning=FALSE, cache=TRUE}
library("caret")
## remove and reload data to undo my earlier changes
rm(spam) 
data("spam", package="kernlab")
```

## Set Up Training and Test Data

```{r, message=FALSE, warning=FALSE, cache=TRUE}
set.seed(201)
inTrain <- createDataPartition(y=spam$type, p=0.6, 
                               list=FALSE)
training <-spam[inTrain,]
testing <- spam[-inTrain,]
```

## Fit Logistic Model

```{r, message=FALSE, warning=FALSE, cache=TRUE}
modelFit_glm <- train(type ~., data=training, method="glm")
modelFit_glm
```

## Evaluate Logistic

```{r, message=FALSE, warning=FALSE, cache=TRUE}
predictions <- predict(modelFit_glm, newdata=testing)
confusionMatrix(predictions, testing$type)
```

## Fit Support Vector Machine

```{r, message=FALSE, warning=FALSE, cache=TRUE}
modelFit_svm <- train(type ~., data=training, method="svmLinear")
modelFit_svm
```

## Evaluate SVM

```{r, message=FALSE, warning=FALSE, cache=TRUE}
predictions <- predict(modelFit_svm, newdata=testing)
confusionMatrix(predictions, testing$type)
```

## Fit Classification Tree Model

```{r, message=FALSE, warning=FALSE, cache=TRUE}
modelFit_rpart <- train(type ~., data=training, method="rpart")
modelFit_rpart
```

## Evaluate Classification Tree

```{r, message=FALSE, warning=FALSE, cache=TRUE}
predictions <- predict(modelFit_rpart, newdata=testing)
confusionMatrix(predictions, testing$type)
```

# Extras

## License

<https://github.com/SML201/lectures/blob/master/LICENSE.md>

## Source Code

<https://github.com/SML201/lectures/tree/master/week11>

## Session Information

<section style="font-size: 0.75em;">
```{r}
sessionInfo()
```
</section>

```{r converttonotes, include=FALSE, cache=FALSE}
source("../customization/make_notes.R")
```
